{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOlY9ruCFgYTmyYFXcS6xZl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kavish1504/Sampling-Techniques/blob/main/102317012_Sampling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATajT5Q_jRoy",
        "outputId": "0a9fd1d2-b743-4922-f78e-61288df84dc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2521762024.py:25: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  return df.groupby(\"Class\", group_keys=False).apply(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Table:\n",
            "       Sampling1_SimpleRandom Sampling2_Stratified Sampling3_Systematic  \\\n",
            "Model1                  88.41                92.75                87.58   \n",
            "Model2                   97.1                97.83                98.69   \n",
            "Model3                  97.83                100.0                100.0   \n",
            "Model4                  67.39                70.29                 71.9   \n",
            "Model5                  69.57                68.84                72.55   \n",
            "\n",
            "       Sampling4_Cluster Sampling5_Bootstrap  \n",
            "Model1             96.83               95.65  \n",
            "Model2             100.0               98.91  \n",
            "Model3             100.0               100.0  \n",
            "Model4             100.0               77.17  \n",
            "Model5             88.89               73.91  \n",
            "Best Sampling Technique for Each Model:\n",
            "Model1       Sampling4_Cluster\n",
            "Model2       Sampling4_Cluster\n",
            "Model3    Sampling2_Stratified\n",
            "Model4       Sampling4_Cluster\n",
            "Model5       Sampling4_Cluster\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.cluster import KMeans\n",
        "data=pd.read_csv(\n",
        "    \"https://raw.githubusercontent.com/AnjulaMehto/Sampling_Assignment/main/Creditcard_data.csv\"\n",
        ")\n",
        "X=data.drop(\"Class\", axis=1)\n",
        "y=data[\"Class\"]\n",
        "ros=RandomOverSampler(random_state=42)\n",
        "X_bal, y_bal=ros.fit_resample(X, y)\n",
        "balanced_df=pd.concat([X_bal, y_bal], axis=1)\n",
        "def simple_random_sampling(df, frac=0.3, seed=42):\n",
        "    return df.sample(frac=frac, random_state=seed)\n",
        "\n",
        "def stratified_sampling(df, frac=0.3, seed=42):\n",
        "    return df.groupby(\"Class\", group_keys=False).apply(\n",
        "        lambda x: x.sample(frac=frac, random_state=seed)\n",
        "    )\n",
        "\n",
        "def systematic_sampling(df, step=3):\n",
        "    return df.iloc[::step]\n",
        "\n",
        "def cluster_sampling(df, n_clusters=10, clusters_to_pick=3, seed=42):\n",
        "    features=df.drop(\"Class\", axis=1)\n",
        "    kmeans=KMeans(n_clusters=n_clusters, random_state=seed)\n",
        "\n",
        "    df = df.copy()\n",
        "    df[\"cluster\"]=kmeans.fit_predict(features)\n",
        "\n",
        "    chosen_clusters=np.random.RandomState(seed).choice(\n",
        "        n_clusters, clusters_to_pick, replace=False\n",
        "    )\n",
        "\n",
        "    return df[df[\"cluster\"].isin(chosen_clusters)].drop(\"cluster\", axis=1)\n",
        "\n",
        "def bootstrap_sampling(df, n_samples, seed=42):\n",
        "    return df.sample(n=n_samples, replace=True, random_state=seed)\n",
        "\n",
        "samples={\n",
        "    \"Sampling1_SimpleRandom\": simple_random_sampling(balanced_df, 0.3),\n",
        "    \"Sampling2_Stratified\": stratified_sampling(balanced_df, 0.3),\n",
        "    \"Sampling3_Systematic\": systematic_sampling(balanced_df, 3),\n",
        "    \"Sampling4_Cluster\": cluster_sampling(balanced_df, 10, 3),\n",
        "    \"Sampling5_Bootstrap\": bootstrap_sampling(\n",
        "        balanced_df, int(0.2 * len(balanced_df))\n",
        "    ),\n",
        "}\n",
        "models={\n",
        "    \"Model1\": LogisticRegression(max_iter=5000),\n",
        "    \"Model2\": DecisionTreeClassifier(),\n",
        "    \"Model3\": RandomForestClassifier(),\n",
        "    \"Model4\": GaussianNB(),\n",
        "    \"Model5\": SVC(),\n",
        "}\n",
        "\n",
        "results=pd.DataFrame(index=models.keys(), columns=samples.keys())\n",
        "for samp_key, samp_df in samples.items():\n",
        "\n",
        "    X=samp_df.drop(\"Class\", axis=1)\n",
        "    y=samp_df[\"Class\"]\n",
        "\n",
        "    X_train, X_test, y_train, y_test=train_test_split(\n",
        "        X, y, test_size=0.3, random_state=42\n",
        "    )\n",
        "\n",
        "    scaler=StandardScaler()\n",
        "    X_train_scaled=scaler.fit_transform(X_train)\n",
        "    X_test_scaled=scaler.transform(X_test)\n",
        "\n",
        "    for model_key, model in models.items():\n",
        "        if model_key in [\"M1\", \"M5\"]:\n",
        "            model.fit(X_train_scaled, y_train)\n",
        "            y_pred=model.predict(X_test_scaled)\n",
        "        else:\n",
        "            model.fit(X_train, y_train)\n",
        "            y_pred = model.predict(X_test)\n",
        "\n",
        "        results.loc[model_key, samp_key]=round(\n",
        "            accuracy_score(y_test, y_pred) * 100, 2\n",
        "        )\n",
        "\n",
        "print(\"Accuracy Table:\")\n",
        "print(results)\n",
        "best_sampling=results.astype(float).idxmax(axis=1)\n",
        "print(\"Best Sampling Technique for Each Model:\")\n",
        "print(best_sampling)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1D_ne3fFj_rr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}